2016-12-23 15:46:57 INFO  DummyLogger$:23 - 1482488217273 configurationFilePath = /D:/workspace/OBS_PN_Common/TicketEnrichi/target/test-classes/
2016-12-23 15:46:57 INFO  DummyLogger$:25 - 1482488217276 *******************
2016-12-23 15:46:57 INFO  DummyLogger$:26 - 1482488217276 *** BEFORE TEST ***
2016-12-23 15:46:57 INFO  DummyLogger$:27 - 1482488217276 *******************
2016-12-23 15:46:57 INFO  DummyLogger$:32 - This is a Windows environment
2016-12-23 15:46:57 INFO  Utils$:29 - 1482488217503 ### LOADING UTILS CLASS ###
2016-12-23 15:46:57 DEBUG Utils$:37 - ### LOADING LOCAL CONFIG ###
2016-12-23 15:46:57 INFO  Utils$:70 - 1482488217504 ### LOADING CONFIG FROM LOCAL ###
2016-12-23 15:46:57 INFO  Utils$:73 - 1482488217505 local = D:\workspace\OBS_PN_Common\TicketEnrichi\target\test-classes\..\..\..\application_dev.conf
2016-12-23 15:46:57 DEBUG Utils$:75 - 1482488217505 loading local config
2016-12-23 15:46:57 INFO  Utils$:45 - 1482488217810 ### LOADING DEFAULT CONFIG ###
2016-12-23 15:46:58 INFO  Utils$:48 - 1482488218177 ### SET SPARK LOCAL MODE ###
2016-12-23 15:46:59 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-23 15:47:02 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2016-12-23 15:47:03 INFO  Utils$:54 - 1482488223144 ### CREATE SPARK CONTEXT ###
2016-12-23 15:47:28 WARN  ObjectStore:6666 - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
2016-12-23 15:47:28 WARN  ObjectStore:568 - Failed to get database default, returning NoSuchObjectException
2016-12-23 15:47:29 WARN  :139 - Your hostname, DIN35003131 resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:a4c:45e5%net4, but we couldn't find any external IP address!
2016-12-23 15:47:36 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-23 15:48:17 WARN  ObjectStore:6666 - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
2016-12-23 15:48:18 WARN  ObjectStore:568 - Failed to get database default, returning NoSuchObjectException
2016-12-23 15:48:18 WARN  :139 - Your hostname, DIN35003131 resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:a4c:45e5%net4, but we couldn't find any external IP address!
2016-12-23 15:48:26 INFO  Utils$:58 - 1482488306058 ### CREATE HIVE CONTEXT ###
2016-12-23 15:48:29 INFO  DummyLogger$:48 - 1482488309017 *******************
2016-12-23 15:48:29 INFO  DummyLogger$:67 - 1482488309018 ******************************
2016-12-23 15:48:29 INFO  DummyLogger$:68 - 1482488309018 *** EXECUTE TICKET ENRICHI ***
2016-12-23 15:48:29 INFO  DummyLogger$:69 - 1482488309018 ******************************
2016-12-23 15:48:29 DEBUG DummyLogger$:71 - 1482488309018 Start of ticketenrichi 
2016-12-23 15:48:29 INFO  Launcher$:68 - remove lkpRepetitif
2016-12-23 15:48:33 INFO  Launcher$:71 - remove ticketEnrich
2016-12-23 15:48:33 INFO  Launcher$:74 - loading TIMESTAMP FOSAV
2016-12-23 15:48:34 DEBUG Acquisition$:72 - 1482488314093 Property : dev.fosav
2016-12-23 15:48:34 DEBUG Acquisition$:74 - 1482488314095 Filename : ../../src/test/ressources/dataset1_TEST/incidentologie_FOSAV_TEST.csv
2016-12-23 15:48:34 INFO  Acquisition$:112 - 1482488314095 Start loading : ../../src/test/ressources/dataset1_TEST/incidentologie_FOSAV_TEST.csv
2016-12-23 15:48:40 INFO  Acquisition$:132 - 1482488318042 End loading : ../../src/test/ressources/dataset1_TEST/incidentologie_FOSAV_TEST.csv with 6943 lines
2016-12-23 15:48:40 INFO  Launcher$:77 - loading TIMESTAMP WASAC => NO
2016-12-23 15:48:40 DEBUG Acquisition$:83 - 1482488320399 Property : dev.intermediateFosavWasac
2016-12-23 15:48:40 DEBUG Acquisition$:85 - 1482488320400 Filename : CSV/intermediateFOSAVWASAC.csv
2016-12-23 15:48:40 INFO  Acquisition$:112 - 1482488320400 Start loading : CSV/intermediateFOSAVWASAC.csv
2016-12-23 15:48:40 ERROR Acquisition$:137 - 1482488320425 Unable to load file CSV/intermediateFOSAVWASAC.csv
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/D:/workspace/OBS_PN_Common/TicketEnrichi/target/CSV/intermediateFOSAVWASAC.csv
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:251)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:270)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:207)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1281)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)
	at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1316)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)
	at org.apache.spark.rdd.RDD.first(RDD.scala:1315)
	at com.databricks.spark.csv.CsvRelation.firstLine$lzycompute(CsvRelation.scala:269)
	at com.databricks.spark.csv.CsvRelation.firstLine(CsvRelation.scala:265)
	at com.databricks.spark.csv.CsvRelation.inferSchema(CsvRelation.scala:242)
	at com.databricks.spark.csv.CsvRelation.<init>(CsvRelation.scala:74)
	at com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:171)
	at com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:44)
	at org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:125)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:114)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:104)
	at com.obs.pn.acq.Acquisition$.loadDataFile(Acquisition.scala:130)
	at com.obs.pn.acq.Acquisition$.loadFile(Acquisition.scala:101)
	at com.obs.pn.ticketenrichi.transf.Launcher$.ticketenrichi(Launcher.scala:81)
	at com.obs.pn.ticketenrichi.MainTestIT.ticketenrichi(MainTestIT.scala:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)
2016-12-23 15:48:40 INFO  Launcher$:83 - loading TIMESTAMP ACORT
2016-12-23 15:48:40 DEBUG Acquisition$:72 - 1482488320429 Property : dev.acort
2016-12-23 15:48:40 DEBUG Acquisition$:74 - 1482488320429 Filename : ../../src/test/ressources/dataset1_TEST/acort_TEST.csv
2016-12-23 15:48:40 INFO  Acquisition$:112 - 1482488320430 Start loading : ../../src/test/ressources/dataset1_TEST/acort_TEST.csv
2016-12-23 15:49:00 INFO  Acquisition$:132 - 1482488335933 End loading : ../../src/test/ressources/dataset1_TEST/acort_TEST.csv with 267440 lines
2016-12-23 15:49:00 INFO  Launcher$:86 - loading TIMESTAMP WASAC IAI
2016-12-23 15:49:00 DEBUG Acquisition$:72 - 1482488340664 Property : dev.wasac_iai
2016-12-23 15:49:00 DEBUG Acquisition$:74 - 1482488340666 Filename : ../../src/test/ressources/dataset1_TEST/incidentologie_wasac_iai_TEST.csv
2016-12-23 15:49:00 INFO  Acquisition$:112 - 1482488340667 Start loading : ../../src/test/ressources/dataset1_TEST/incidentologie_wasac_iai_TEST.csv
2016-12-23 15:49:11 INFO  Acquisition$:132 - 1482488351188 End loading : ../../src/test/ressources/dataset1_TEST/incidentologie_wasac_iai_TEST.csv with 86015 lines
2016-12-23 15:49:11 INFO  Launcher$:89 - loading REFERENTIAL COMMUNES
2016-12-23 15:49:11 DEBUG Acquisition$:83 - 1482488351629 Property : dev.communes
2016-12-23 15:49:11 DEBUG Acquisition$:85 - 1482488351630 Filename : ../../src/test/ressources/referential/communes_INSEE_utile.csv
2016-12-23 15:49:11 INFO  Acquisition$:112 - 1482488351630 Start loading : ../../src/test/ressources/referential/communes_INSEE_utile.csv
2016-12-23 15:49:12 INFO  Acquisition$:132 - 1482488351991 End loading : ../../src/test/ressources/referential/communes_INSEE_utile.csv with 36706 lines
2016-12-23 15:49:12 INFO  Launcher$:92 - loading REFERENTIAL CORRESPONDANCE INSEE
2016-12-23 15:49:12 DEBUG Acquisition$:83 - 1482488352143 Property : dev.correspondance_insee
2016-12-23 15:49:12 DEBUG Acquisition$:85 - 1482488352144 Filename : ../../src/test/ressources/referential/correspondance-code-insee-code-postal_utile.csv
2016-12-23 15:49:12 INFO  Acquisition$:112 - 1482488352144 Start loading : ../../src/test/ressources/referential/correspondance-code-insee-code-postal_utile.csv
2016-12-23 15:49:13 INFO  Acquisition$:132 - 1482488353843 End loading : ../../src/test/ressources/referential/correspondance-code-insee-code-postal_utile.csv with 36822 lines
2016-12-23 15:49:13 INFO  Launcher$:95 - loading REFERENTIAL RAP REFRENCE
2016-12-23 15:49:13 DEBUG Acquisition$:83 - 1482488353952 Property : dev.rapReference
2016-12-23 15:49:13 DEBUG Acquisition$:85 - 1482488353952 Filename : ../../src/test/ressources/referential/AllRapReference.csv
2016-12-23 15:49:13 INFO  Acquisition$:112 - 1482488353952 Start loading : ../../src/test/ressources/referential/AllRapReference.csv
2016-12-23 15:49:15 INFO  Acquisition$:132 - 1482488355609 End loading : ../../src/test/ressources/referential/AllRapReference.csv with 765 lines
2016-12-23 15:49:15 INFO  Launcher$:98 - loading REFERENTIAL INCIDENTS => NO
2016-12-23 15:49:15 INFO  Launcher$:101 - loading REFERENTIAL NRGTR
2016-12-23 15:49:15 DEBUG Acquisition$:83 - 1482488355721 Property : dev.NRGTRreferentiel
2016-12-23 15:49:15 DEBUG Acquisition$:85 - 1482488355722 Filename : ../../src/test/ressources/referential/NRGTRreferentiel.csv
2016-12-23 15:49:15 INFO  Acquisition$:112 - 1482488355722 Start loading : ../../src/test/ressources/referential/NRGTRreferentiel.csv
2016-12-23 15:49:15 INFO  Acquisition$:132 - 1482488355836 End loading : ../../src/test/ressources/referential/NRGTRreferentiel.csv with 24 lines
2016-12-23 15:49:15 INFO  Launcher$:104 - loading REFERENTIAL LKP REPETITIF
2016-12-23 15:49:15 DEBUG Acquisition$:83 - 1482488355907 Property : dev.lkp_repetitifs
2016-12-23 15:49:15 DEBUG Acquisition$:85 - 1482488355907 Filename : ../../src/test/ressources/referential/LKP_REPETITIFS.csv
2016-12-23 15:49:15 INFO  Acquisition$:112 - 1482488355908 Start loading : ../../src/test/ressources/referential/LKP_REPETITIFS.csv
2016-12-23 15:49:15 ERROR Acquisition$:137 - 1482488355953 Unable to load file ../../src/test/ressources/referential/LKP_REPETITIFS.csv
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/D:/workspace/OBS_PN_Common/src/test/ressources/referential/LKP_REPETITIFS.csv
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:251)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:270)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:207)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1281)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)
	at org.apache.spark.rdd.RDD.take(RDD.scala:1276)
	at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1316)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)
	at org.apache.spark.rdd.RDD.first(RDD.scala:1315)
	at com.databricks.spark.csv.CsvRelation.firstLine$lzycompute(CsvRelation.scala:269)
	at com.databricks.spark.csv.CsvRelation.firstLine(CsvRelation.scala:265)
	at com.databricks.spark.csv.CsvRelation.inferSchema(CsvRelation.scala:235)
	at com.databricks.spark.csv.CsvRelation.<init>(CsvRelation.scala:74)
	at com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:171)
	at com.databricks.spark.csv.DefaultSource.createRelation(DefaultSource.scala:44)
	at org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:125)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:114)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:104)
	at com.obs.pn.acq.Acquisition$.loadDataFile(Acquisition.scala:130)
	at com.obs.pn.acq.Acquisition$.loadFile(Acquisition.scala:101)
	at com.obs.pn.ticketenrichi.transf.Launcher$.ticketenrichi(Launcher.scala:106)
	at com.obs.pn.ticketenrichi.MainTestIT.ticketenrichi(MainTestIT.scala:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)
2016-12-23 15:49:16 INFO  Launcher$:111 - loading LKP ACTIVATION
2016-12-23 15:49:18 INFO  Launcher$:114 - loading SOIPAD
2016-12-23 15:49:19 INFO  Launcher$:117 - *** loadings ARE DONE ***
2016-12-23 15:49:19 INFO  Launcher$:119 - Stopping for now, some files are not loaded...
2016-12-23 15:49:19 DEBUG DummyLogger$:75 - 1482488359110 End of ticketenrichi
2016-12-23 15:49:19 INFO  DummyLogger$:54 - 1482488359110 ******************
2016-12-23 15:49:19 INFO  DummyLogger$:55 - 1482488359110 *** AFTER TEST ***
2016-12-23 15:49:19 INFO  DummyLogger$:56 - 1482488359110 ******************
2016-12-23 15:49:19 INFO  DummyLogger$:60 - 1482488359114 ******************
2016-12-23 15:49:19 ERROR ShutdownHookManager:96 - Exception while deleting Spark temp dir: C:\Users\sabarm\AppData\Local\Temp\spark-73f8fbff-2c60-491e-b1ac-7c850378999d
java.io.IOException: Failed to delete: C:\Users\sabarm\AppData\Local\Temp\spark-73f8fbff-2c60-491e-b1ac-7c850378999d
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:884)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:63)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:60)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:60)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:264)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:234)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:234)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:234)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1699)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:234)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:234)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:234)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:234)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:216)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
